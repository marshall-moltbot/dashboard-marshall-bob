# Overnight AI Hallucination & Error News — Feb 17, 2026

1. **Human-AI “Co-Hallucinations”**
   - New research argues that we don't just receive AI hallucinations—we're “hallucinating with” AI, developing distributed delusions or “AI psychosis,” especially as users rely more on AI-generated content.
   - Raises concerns about collective reasoning and responsibility as AI becomes embedded in decision-making.
   - Source: [Philosophy & Technology, 2026](https://studyfinds.com/ai-hallucinates-and-we-hallucinate-too/)

2. **Hallucination Discoveries in Top AI Research**
   - GPTZero found over 50 hallucinated citations in academic papers under review for ICLR 2026—errors that peer reviewers missed.
   - Underscores ongoing risks: even experts fail to spot sophisticated AI-generated errors.
   - Source: [GPTZero News, Jan 2026](https://gptzero.me/news/iclr-2026/)

3. **2026 AI Safety Report: Hallucinations & Reliability**
   - International AI Safety Report highlights that language models still “make stuff up,” particularly in multi-step or real-world reasoning.
   - Performance remains inconsistent; hallucinations continue to be a core risk in critical applications.
   - Source: [International AI Safety Report, Feb 2026](https://www.insideglobaltech.com/2026/02/10/international-ai-safety-report-2026-examines-ai-capabilities-risks-and-safeguards/)
